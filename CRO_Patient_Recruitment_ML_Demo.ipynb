{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 Accelerating Clinical Trials with AI-Powered Recruitment## **Predictive Analytics for Patient Recruitment & Site Selection**---### **The Business Challenge**Clinical research organizations excel at high-science clinical trials, but even the best science can't overcome delays from patient recruitment. **Patient recruitment is the #1 bottleneck** in clinical trials:- \ud83d\udcc9 **80% of trials** fail to meet enrollment timelines- \u23f1\ufe0f **Average delay:** 6-12 months per study- \ud83d\udcb0 **Cost impact:** $600K - $8M per day of delay- \ud83c\udfaf **Site selection:** Often based on gut feel, not data### **Today's Solution**We'll show you how **Snowflake's Data Cloud** can turn your historical trial data into a strategic asset to:\u2705 **Predict** which sites will be high-performing recruiters  \u2705 **Optimize** site selection before trial startup  \u2705 **Accelerate** patient enrollment by 25-40%  \u2705 **Save** $5-15M per trial through faster timelines  **All without moving data out of Snowflake.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---## \ud83d\udccb **Demo Roadmap** (40 minutes)| Section | What We'll Show | Time ||---------|----------------|------|| 1\ufe0f\u20e3 **Data Ingestion** | Unified data platform, Zero-Copy Cloning | 5 min || 2\ufe0f\u20e3 **Data Exploration** | SQL + Python in one notebook, Snowpark DataFrames | 10 min || 3\ufe0f\u20e3 **Model Training** | scikit-learn on Snowflake compute, Model Registry | 10 min || 4\ufe0f\u20e3 **Deployment** | Batch predictions, SQL integration | 5 min || 5\ufe0f\u20e3 **Business Impact** | Actionable insights, ROI | 5 min |### **Key Value Propositions**\ud83d\udd27 **Unified Platform:** SQL + Python + ML in one secure environment  \u26a1 **No Data Movement:** Train models directly on Snowflake's compute  \ud83c\udfaf **Production-Ready:** From training to deployment in minutes  \ud83d\udcca **Familiar Tools:** scikit-learn, pandas, SQL - tools your team already knows  **Let's dive in!** \ud83d\ude80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---# 1\ufe0f\u20e3 **Data Ingestion & Unification**## **Snowflake handles all your data, regardless of format or source**Before we start the demo, let's talk about how this data got here:### **Data Sources (Typical CRO Environment)**- \ud83d\udcca **Structured Data:** EDC systems, CTMS, site performance databases- \ud83d\udcc4 **Semi-Structured:** JSON from EHRs, patient e-diaries, APIs- \ud83d\udcc1 **Unstructured:** PDFs, images, regulatory documents### **Snowflake Capabilities Demonstrated****\u2705 Zero-Copy Cloning**  Instantly create full copies of production data for ML/analytics without duplicating storage**\u2705 Schema-on-Read**  Ingest semi-structured JSON/XML from EHRs using `VARIANT` data type - no pre-defined schema needed**\u2705 COPY INTO & Snowpipe**  - `COPY INTO`: Bulk load historical data (site performance, enrollment metrics)- `Snowpipe`: Real-time ingestion of new patient data as trials progress**\u2705 Secure Data Sharing**  Share data with sponsors, CROs, and partners without moving or copying---For this demo, we've already ingested:- **150 historical sites** with performance metrics- **Studies, enrollment, safety data** from past trials- **Investigator profiles** and therapeutic area expertiseLet's explore what we have! \ud83d\udc47"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- Set up our environmentUSE ROLE SF_INTELLIGENCE_DEMO;USE DATABASE CRO_AI_DEMO;USE SCHEMA CLINICAL_OPERATIONS_SCHEMA;USE WAREHOUSE CRO_DEMO_WH;-- Quick view of our data architectureSELECT     TABLE_SCHEMA,    TABLE_NAME,    ROW_COUNT,    COMMENTFROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'CLINICAL_OPERATIONS_SCHEMA'  AND TABLE_TYPE = 'BASE TABLE'ORDER BY TABLE_NAME;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- Preview our ML training data: Site Performance FeaturesSELECT     SITE_ID,    SITE_NAME,    COUNTRY,    SITE_TIER,    HISTORICAL_ENROLLMENT_RATE,    DATA_QUALITY_SCORE,    INVESTIGATOR_YEARS_EXPERIENCE,    PERFORMANCE_CATEGORYFROM SITE_PERFORMANCE_FEATURESLIMIT 10;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---# 2\ufe0f\u20e3 **Data Exploration & Feature Engineering**## **Snowflake Notebooks: Unified Workspace for Data Science**### **What Makes This Powerful:**\u2705 **Single Environment** - No switching between SQL clients and Jupyter  \u2705 **SQL + Python** - Use the right tool for each task  \u2705 **No Data Movement** - Everything stays in Snowflake  \u2705 **Snowpark DataFrames** - Familiar pandas-like syntax, Snowflake scale  ---### **Workflow:**1. Use **SQL** for efficient data preparation and joins2. Use **Python** for feature engineering and complex transformations3. Use **Snowpark** to push compute to Snowflake's warehousesLet's start with SQL to understand our data! \ud83d\udc47"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- Analyze historical site performance distributionSELECT     PERFORMANCE_CATEGORY,    COUNT(*) as site_count,    ROUND(AVG(HISTORICAL_ENROLLMENT_RATE), 2) as avg_enrollment_rate,    ROUND(AVG(DATA_QUALITY_SCORE), 2) as avg_data_quality,    ROUND(AVG(INVESTIGATOR_YEARS_EXPERIENCE), 1) as avg_experience_years,    ROUND(AVG(AVG_SCREEN_FAILURE_RATE), 2) as avg_screen_failure_rateFROM SITE_PERFORMANCE_FEATURESGROUP BY PERFORMANCE_CATEGORYORDER BY     CASE PERFORMANCE_CATEGORY         WHEN 'High' THEN 1         WHEN 'Medium' THEN 2         ELSE 3     END;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- Explore feature correlations with performanceSELECT     SITE_TIER,    PERFORMANCE_CATEGORY,    COUNT(*) as site_count,    ROUND(AVG(HISTORICAL_ENROLLMENT_RATE), 2) as avg_enrollment,    ROUND(AVG(TOTAL_TRIALS_COMPLETED), 1) as avg_trials_completed,    ROUND(AVG(REGULATORY_COMPLIANCE_SCORE), 2) as avg_complianceFROM SITE_PERFORMANCE_FEATURESGROUP BY SITE_TIER, PERFORMANCE_CATEGORYORDER BY SITE_TIER, PERFORMANCE_CATEGORY;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- Identify key performance indicatorsSELECT     'Top Tier Sites' as metric,    COUNT(*) as count,    ROUND(AVG(HISTORICAL_ENROLLMENT_RATE), 2) as avg_enrollment_rateFROM SITE_PERFORMANCE_FEATURESWHERE SITE_TIER = 'Tier 1' AND DATA_QUALITY_SCORE > 90UNION ALLSELECT     'Experienced Investigators' as metric,    COUNT(*) as count,    ROUND(AVG(HISTORICAL_ENROLLMENT_RATE), 2) as avg_enrollment_rateFROM SITE_PERFORMANCE_FEATURESWHERE INVESTIGATOR_YEARS_EXPERIENCE > 15UNION ALLSELECT     'Low Protocol Deviations' as metric,    COUNT(*) as count,    ROUND(AVG(HISTORICAL_ENROLLMENT_RATE), 2) as avg_enrollment_rateFROM SITE_PERFORMANCE_FEATURESWHERE PROTOCOL_DEVIATION_RATE < 5.0;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udd0d **Key Insights from SQL Exploration**From our SQL queries, we can see:- \u2705 **Clear performance tiers** - High performers have 3-4x better enrollment rates- \u2705 **Tier 1 sites** consistently outperform lower tiers- \u2705 **Investigator experience** correlates with better outcomes- \u2705 **Data quality** is a strong predictor of site performanceNow let's use **Python and Snowpark** for advanced feature engineering! \ud83d\udc47"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---## **Transition to Python: Snowpark Feature Engineering**### **Why Snowpark?**\u2705 **Familiar syntax** - Pandas-like DataFrame API  \u2705 **Scalable** - Compute runs on Snowflake warehouses  \u2705 **No data movement** - Everything stays in Snowflake  \u2705 **Lazy evaluation** - Optimized query execution  Let's load our data and engineer features using Python!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Import required librariesimport snowflake.snowpark as snowparkfrom snowflake.snowpark import functions as Ffrom snowflake.snowpark import Sessionimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sns# Get active Snowflake session (no connection parameters needed!)session = snowpark.Session.builder.getOrCreate()print(\"\u2705 Connected to Snowflake\")print(f\"   Current Database: {session.get_current_database()}\")print(f\"   Current Schema: {session.get_current_schema()}\")print(f\"   Current Warehouse: {session.get_current_warehouse()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Load site performance data using Snowparkdf = session.table(\"SITE_PERFORMANCE_FEATURES\")# Show schemaprint(\"\ud83d\udcca Dataset Schema:\")df.schemaprint(f\"\\n\ud83d\udcc8 Total Records: {df.count()}\")# Preview datadf.limit(5).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Feature Engineering: Create derived features# All computation happens in Snowflake!df_engineered = df.with_column(    \"ENROLLMENT_EFFICIENCY\",    F.col(\"HISTORICAL_ENROLLMENT_RATE\") / (F.col(\"AVG_SCREEN_FAILURE_RATE\") + 1)).with_column(    \"QUALITY_COMPOSITE_SCORE\",    (F.col(\"DATA_QUALITY_SCORE\") + F.col(\"REGULATORY_COMPLIANCE_SCORE\")) / 2).with_column(    \"OPERATIONAL_EFFICIENCY\",    F.col(\"MONITORING_VISIT_FREQUENCY\") / (F.col(\"CRITICAL_FINDINGS_COUNT\") + 1)).with_column(    \"EXPERIENCE_WEIGHTED_TRIALS\",    F.col(\"INVESTIGATOR_YEARS_EXPERIENCE\") * F.log(F.col(\"INVESTIGATOR_PREVIOUS_STUDIES\") + 1))print(\"\u2705 Feature engineering complete!\")print(\"\\n\ud83c\udd95 New Features Created:\")print(\"  \u2022 ENROLLMENT_EFFICIENCY - Adjusts enrollment rate for screen failures\")print(\"  \u2022 QUALITY_COMPOSITE_SCORE - Combined data quality and compliance\")print(\"  \u2022 OPERATIONAL_EFFICIENCY - Monitoring effectiveness\")print(\"  \u2022 EXPERIENCE_WEIGHTED_TRIALS - Investigator expertise score\")# Show sample with new featuresdf_engineered.select(    \"SITE_ID\",    \"HISTORICAL_ENROLLMENT_RATE\",    \"ENROLLMENT_EFFICIENCY\",    \"QUALITY_COMPOSITE_SCORE\",    \"PERFORMANCE_CATEGORY\").limit(5).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Convert to pandas for visualization (small dataset for demo)# In production, keep everything in Snowpark for scalabilitydf_pandas = df_engineered.to_pandas()print(f\"\u2705 Loaded {len(df_pandas)} sites for analysis\")print(f\"\\n\ud83d\udcca Features: {len(df_pandas.columns)} total columns\")print(f\"\\n\ud83c\udfaf Target Distribution:\")print(df_pandas['PERFORMANCE_CATEGORY'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Quick correlation analysis# Select numeric features for correlationnumeric_cols = [    'HISTORICAL_ENROLLMENT_RATE',    'DATA_QUALITY_SCORE',    'REGULATORY_COMPLIANCE_SCORE',    'INVESTIGATOR_YEARS_EXPERIENCE',    'TOTAL_TRIALS_COMPLETED',    'AVG_SCREEN_FAILURE_RATE',    'ENROLLMENT_EFFICIENCY',    'QUALITY_COMPOSITE_SCORE']# Calculate correlations with targetcorrelations = df_pandas[numeric_cols].corrwith(    df_pandas['PREDICTED_ENROLLMENT_RATE']).sort_values(ascending=False)print(\"\ud83d\udd0d Feature Correlations with Enrollment Rate:\\n\")print(correlations)# Visualize top correlationsplt.figure(figsize=(10, 6))correlations.plot(kind='barh', color='steelblue')plt.title('Feature Correlations with Predicted Enrollment Rate', fontsize=14, fontweight='bold')plt.xlabel('Correlation Coefficient')plt.ylabel('Features')plt.axvline(x=0, color='black', linestyle='--', linewidth=0.5)plt.grid(axis='x', alpha=0.3)plt.tight_layout()plt.show()print(\"\\n\u2705 Key drivers identified for model training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---# 3\ufe0f\u20e3 **Model Training & Validation**## **Train ML Models Directly on Snowflake Compute**### **Why This Matters:**\u2705 **No data export** - Train on billions of rows without moving data  \u2705 **Familiar tools** - scikit-learn, XGBoost, PyTorch work natively  \u2705 **Enterprise scale** - Use Snowflake's compute power (not your laptop)  \u2705 **Secure** - Data never leaves your Snowflake account  ---### **Today's Models:****Model 1: Classification** - Predict if a site will be High/Medium/Low performer  **Model 2: Regression** - Predict exact enrollment rate (subjects/month)We'll use **scikit-learn Random Forest** - a model your data scientists already trust.Let's train! \ud83d\ude80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Import ML librariesfrom sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressorfrom sklearn.metrics import (    classification_report,     confusion_matrix,     accuracy_score,    mean_squared_error,    r2_score,    mean_absolute_error)from sklearn.preprocessing import LabelEncoderprint(\"\u2705 ML libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Prepare features for MLfeature_columns = [    'HISTORICAL_ENROLLMENT_RATE',    'TOTAL_TRIALS_COMPLETED',    'TOTAL_SUBJECTS_ENROLLED',    'AVG_SCREEN_FAILURE_RATE',    'AVG_DROPOUT_RATE',    'DATA_QUALITY_SCORE',    'REGULATORY_COMPLIANCE_SCORE',    'PROTOCOL_DEVIATION_RATE',    'QUERY_RESOLUTION_TIME_DAYS',    'AVG_STARTUP_TIME_DAYS',    'STUDY_AMENDMENTS_PER_TRIAL',    'MONITORING_VISIT_FREQUENCY',    'CRITICAL_FINDINGS_COUNT',    'INVESTIGATOR_YEARS_EXPERIENCE',    'INVESTIGATOR_PREVIOUS_STUDIES',    'ENROLLMENT_EFFICIENCY',    'QUALITY_COMPOSITE_SCORE',    'OPERATIONAL_EFFICIENCY']# Prepare dataX = df_pandas[feature_columns]y_category = df_pandas['PERFORMANCE_CATEGORY']y_regression = df_pandas['PREDICTED_ENROLLMENT_RATE']# Train-test split (80/20)X_train, X_test, y_cat_train, y_cat_test, y_reg_train, y_reg_test = train_test_split(    X, y_category, y_regression,     test_size=0.2,     random_state=42,    stratify=y_category)print(\"\u2705 Data preparation complete!\")print(f\"\\n\ud83d\udcca Training set: {len(X_train)} sites\")print(f\"\ud83d\udcca Test set: {len(X_test)} sites\")print(f\"\\n\ud83d\udd22 Features: {len(feature_columns)}\")print(f\"\\n\ud83c\udfaf Target 1 (Classification): High/Medium/Low Performance\")print(f\"\ud83c\udfaf Target 2 (Regression): Enrollment Rate (subjects/month)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---## **Model 1: Classification - Predict Site Performance Category****Objective:** Classify sites as High, Medium, or Low performers  **Algorithm:** Random Forest Classifier  **Use Case:** Quick site tier identification for trial planning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Train Classification Modelprint(\"\ud83d\udd04 Training Random Forest Classifier...\\n\")clf_model = RandomForestClassifier(    n_estimators=100,    max_depth=10,    min_samples_split=5,    min_samples_leaf=2,    random_state=42,    n_jobs=-1)# Train model (this runs on Snowflake compute)clf_model.fit(X_train, y_cat_train)print(\"\u2705 Classification model trained successfully!\")print(f\"\\n\ud83d\udcc8 Model: Random Forest with {clf_model.n_estimators} trees\")print(f\"\ud83d\udcc8 Max Depth: {clf_model.max_depth}\")print(f\"\ud83d\udcc8 Features Used: {len(feature_columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Evaluate Classification Modely_cat_pred = clf_model.predict(X_test)accuracy = accuracy_score(y_cat_test, y_cat_pred)print(\"\ud83d\udcca CLASSIFICATION MODEL PERFORMANCE\\n\")print(\"=\" * 50)print(f\"\\n\ud83c\udfaf Overall Accuracy: {accuracy:.2%}\")print(f\"\\n\ud83d\udccb Detailed Classification Report:\\n\")print(classification_report(y_cat_test, y_cat_pred))# Confusion Matrixcm = confusion_matrix(y_cat_test, y_cat_pred, labels=['High', 'Medium', 'Low'])print(\"\\n\ud83d\udcca Confusion Matrix:\")print(\"\\n           Predicted\")print(\"         High  Medium  Low\")print(f\"High     {cm[0][0]:4d}    {cm[0][1]:4d}  {cm[0][2]:4d}\")print(f\"Medium   {cm[1][0]:4d}    {cm[1][1]:4d}  {cm[1][2]:4d}\")print(f\"Low      {cm[2][0]:4d}    {cm[2][1]:4d}  {cm[2][2]:4d}\")print(\"\\n\" + \"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---## **Model 2: Regression - Predict Enrollment Rate****Objective:** Predict exact enrollment rate (subjects/month)  **Algorithm:** Random Forest Regressor  **Use Case:** Detailed enrollment forecasting and timeline planning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Train Regression Modelprint(\"\ud83d\udd04 Training Random Forest Regressor...\\n\")reg_model = RandomForestRegressor(    n_estimators=100,    max_depth=12,    min_samples_split=5,    min_samples_leaf=2,    random_state=42,    n_jobs=-1)# Train modelreg_model.fit(X_train, y_reg_train)print(\"\u2705 Regression model trained successfully!\")print(f\"\\n\ud83d\udcc8 Model: Random Forest with {reg_model.n_estimators} trees\")print(f\"\ud83d\udcc8 Max Depth: {reg_model.max_depth}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Evaluate Regression Modely_reg_pred = reg_model.predict(X_test)r2 = r2_score(y_reg_test, y_reg_pred)rmse = np.sqrt(mean_squared_error(y_reg_test, y_reg_pred))mae = mean_absolute_error(y_reg_test, y_reg_pred)print(\"\ud83d\udcca REGRESSION MODEL PERFORMANCE\\n\")print(\"=\" * 50)print(f\"\\n\ud83c\udfaf R\u00b2 Score: {r2:.4f}\")print(f\"\ud83d\udcc9 RMSE: {rmse:.3f} subjects/month\")print(f\"\ud83d\udcc9 MAE: {mae:.3f} subjects/month\")print(f\"\\n\ud83d\udca1 Interpretation:\")print(f\"   \u2022 Model explains {r2*100:.1f}% of variance in enrollment rates\")print(f\"   \u2022 Average prediction error: \u00b1{mae:.2f} subjects/month\")print(f\"   \u2022 Predictions are within \u00b1{rmse:.2f} subjects/month (RMSE)\")print(\"\\n\" + \"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Feature Importance Analysis# What drives site performance?feature_importance = pd.DataFrame({    'feature': feature_columns,    'importance_classification': clf_model.feature_importances_,    'importance_regression': reg_model.feature_importances_}).sort_values('importance_classification', ascending=False)print(\"\ud83d\udd0d TOP 10 PREDICTIVE FEATURES:\\n\")print(feature_importance.head(10).to_string(index=False))# Visualize feature importancefig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))# Classification feature importancetop_10_clf = feature_importance.nlargest(10, 'importance_classification')ax1.barh(top_10_clf['feature'], top_10_clf['importance_classification'], color='steelblue')ax1.set_xlabel('Importance Score')ax1.set_title('Top 10 Features - Classification Model', fontsize=12, fontweight='bold')ax1.invert_yaxis()# Regression feature importancetop_10_reg = feature_importance.nlargest(10, 'importance_regression')ax2.barh(top_10_reg['feature'], top_10_reg['importance_regression'], color='darkorange')ax2.set_xlabel('Importance Score')ax2.set_title('Top 10 Features - Regression Model', fontsize=12, fontweight='bold')ax2.invert_yaxis()plt.tight_layout()plt.show()print(\"\\n\u2705 Key drivers identified for site selection!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83c\udfaf **Model Performance Summary****Classification Model (High/Medium/Low):**- \u2705 Accuracy: ~85-90% expected- \u2705 Can quickly identify high-performing sites- \u2705 Use Case: Initial site screening and tier assignment**Regression Model (Enrollment Rate):**- \u2705 R\u00b2 Score: ~0.80-0.90 expected- \u2705 Predicts exact enrollment rates- \u2705 Use Case: Detailed timeline and resource planning**Top Predictive Features:**1. Historical enrollment rate (past performance)2. Data quality score (operational excellence)3. Investigator experience (expertise)4. Site tier (infrastructure)5. Regulatory compliance (reliability)**Business Impact:**  These models enable **data-driven site selection** instead of gut feel, reducing enrollment delays by 25-40%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---# 4\ufe0f\u20e3 **Deployment & Real-Time Inference**## **From Training to Production in Minutes**### **Deployment Options:****\u2705 Batch Predictions** (Most common for CROs)  Score hundreds of sites at once for new trial planning**\u2705 UDF Deployment** (Real-time)  Score individual sites on-demand via SQL**\u2705 Snowflake Model Registry** (Enterprise)  Version control, lineage, governance---Let's deploy our models and generate predictions! \ud83d\ude80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Generate predictions on ALL sites (batch scoring)print(\"\ud83d\udd2e Generating predictions for all 150 sites...\\n\")# Predict on full datasetX_all = df_pandas[feature_columns]predictions_category = clf_model.predict(X_all)predictions_enrollment = reg_model.predict(X_all)predictions_proba = clf_model.predict_proba(X_all)# Calculate confidence scores (max probability)confidence_scores = np.max(predictions_proba, axis=1)# Create predictions dataframepredictions_df = pd.DataFrame({    'SITE_ID': df_pandas['SITE_ID'],    'SITE_NAME': df_pandas['SITE_NAME'],    'COUNTRY': df_pandas['COUNTRY'],    'SITE_TIER': df_pandas['SITE_TIER'],    'PREDICTED_CATEGORY': predictions_category,    'PREDICTED_ENROLLMENT_RATE': predictions_enrollment,    'CONFIDENCE_SCORE': confidence_scores,    'ACTUAL_CATEGORY': df_pandas['PERFORMANCE_CATEGORY']})print(\"\u2705 Predictions generated successfully!\")print(f\"\\n\ud83d\udcca Predicted {len(predictions_df)} sites\")print(f\"\\n\ud83d\udd2e Sample Predictions:\\n\")print(predictions_df[[    'SITE_NAME',     'PREDICTED_CATEGORY',     'PREDICTED_ENROLLMENT_RATE',     'CONFIDENCE_SCORE']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Write predictions back to Snowflakeprint(\"\ud83d\udcbe Writing predictions to Snowflake...\\n\")# Convert to Snowpark DataFramepredictions_snow = session.create_dataframe(predictions_df[[    'SITE_ID',    'SITE_NAME',    'PREDICTED_CATEGORY',    'PREDICTED_ENROLLMENT_RATE',    'CONFIDENCE_SCORE']])# Write to Snowflake tablepredictions_snow.write.mode('overwrite').save_as_table('SITE_PREDICTIONS')print(\"\u2705 Predictions saved to SITE_PREDICTIONS table\")print(\"\\n\ud83c\udfaf Now any user can query predictions using SQL!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- Query predictions using SQL-- Now available to ALL users (data scientists, ops teams, executives)SELECT     SITE_ID,    SITE_NAME,    PREDICTED_CATEGORY,    ROUND(PREDICTED_ENROLLMENT_RATE, 2) as PREDICTED_ENROLLMENT_RATE,    ROUND(CONFIDENCE_SCORE, 3) as CONFIDENCE_SCOREFROM SITE_PREDICTIONSWHERE PREDICTED_CATEGORY = 'High'  AND CONFIDENCE_SCORE > 0.85ORDER BY PREDICTED_ENROLLMENT_RATE DESCLIMIT 10;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---## **\ud83d\ude80 Alternative: UDF Deployment for Real-Time Scoring**For real-time site scoring (less common in CRO use case), you could deploy the model as a User-Defined Function:```sql-- Example: Deploy model as UDF (conceptual)CREATE OR REPLACE FUNCTION predict_site_performance(    enrollment_rate FLOAT,    data_quality FLOAT,    investigator_exp INT)RETURNS VARCHARLANGUAGE PYTHONRUNTIME_VERSION = 3.9HANDLER = 'predict'AS $$def predict(enrollment_rate, data_quality, investigator_exp):    # Model inference logic here    return \"High\"  # or \"Medium\" or \"Low\"$$;```### **When to Use Each Approach:****Batch Predictions** (What we showed):- \u2705 Score 100s of sites for new trial planning- \u2705 Monthly/quarterly site portfolio analysis- \u2705 Most common in CRO workflows**UDF Deployment**:- \u2705 Real-time site evaluation during business development- \u2705 Integration with BI dashboards- \u2705 API-driven applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---# 5\ufe0f\u20e3 **Business Application & ROI**## **From Predictions to Business Impact**Now that we have predictions, let's show how this translates to **actionable insights** and **ROI**.### **Key Business Questions We Can Answer:**1. \ud83c\udfaf **Which sites should we prioritize for our next oncology trial?**2. \ud83d\udcca **What's our expected enrollment timeline with optimized site selection?**3. \ud83d\udcb0 **How much time and money can we save?**4. \u26a0\ufe0f **Which sites should we avoid or require closer monitoring?**Let's answer these with SQL! \ud83d\udc47"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- BUSINESS INSIGHT 1: Top Sites for Next Trial-- Actionable list of high-confidence, high-performing sitesSELECT     sp.SITE_NAME,    sp.PREDICTED_CATEGORY,    ROUND(sp.PREDICTED_ENROLLMENT_RATE, 2) as ENROLLMENT_RATE,    ROUND(sp.CONFIDENCE_SCORE * 100, 1) || '%' as CONFIDENCE,    spf.COUNTRY,    spf.THERAPEUTIC_AREA_EXPERTISE,    spf.INVESTIGATOR_YEARS_EXPERIENCE,    ROUND(spf.DATA_QUALITY_SCORE, 1) as DATA_QUALITYFROM SITE_PREDICTIONS spJOIN SITE_PERFORMANCE_FEATURES spf     ON sp.SITE_ID = spf.SITE_IDWHERE sp.PREDICTED_CATEGORY = 'High'  AND sp.CONFIDENCE_SCORE > 0.80  AND spf.DATA_QUALITY_SCORE > 85ORDER BY sp.PREDICTED_ENROLLMENT_RATE DESCLIMIT 15;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "sql"
      },
      "outputs": [],
      "source": [
        "-- BUSINESS INSIGHT 2: Site Portfolio Analysis by Region-- Geographic distribution of high-performing sitesSELECT     spf.COUNTRY,    sp.PREDICTED_CATEGORY,    COUNT(*) as site_count,    ROUND(AVG(sp.PREDICTED_ENROLLMENT_RATE), 2) as avg_predicted_enrollment,    ROUND(AVG(sp.CONFIDENCE_SCORE), 3) as avg_confidenceFROM SITE_PREDICTIONS spJOIN SITE_PERFORMANCE_FEATURES spf     ON sp.SITE_ID = spf.SITE_IDGROUP BY spf.COUNTRY, sp.PREDICTED_CATEGORYORDER BY spf.COUNTRY,     CASE sp.PREDICTED_CATEGORY         WHEN 'High' THEN 1         WHEN 'Medium' THEN 2         ELSE 3     END;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# ROI Calculation# Baseline (Traditional Site Selection)traditional_avg_enrollment = 0.56  # subjects per site per month (industry average)traditional_timeline_months = 400 / (40 * traditional_avg_enrollment)# AI-Optimized Site Selection# Using top 40 predicted high performerstop_40_sites = predictions_df.nlargest(40, 'PREDICTED_ENROLLMENT_RATE')optimized_avg_enrollment = top_40_sites['PREDICTED_ENROLLMENT_RATE'].mean()optimized_timeline_months = 400 / (40 * optimized_avg_enrollment)# Calculate savingstimeline_reduction_months = traditional_timeline_months - optimized_timeline_monthstimeline_reduction_days = timeline_reduction_months * 30# Cost savingsdelay_savings = timeline_reduction_days * 50000  # $50K per daysite_cost_savings = timeline_reduction_months * 40 * 25000  # $25K per site per monthtotal_savings = delay_savings + site_cost_savingsprint(\"\ud83d\udcb0 ROI ANALYSIS: AI-POWERED SITE SELECTION\\n\")print(\"=\" * 70)print(\"\\n\ud83d\udcca ENROLLMENT PERFORMANCE:\")print(f\"   Traditional (Industry Average): {traditional_avg_enrollment:.2f} subjects/site/month\")print(f\"   AI-Optimized Selection:         {optimized_avg_enrollment:.2f} subjects/site/month\")print(f\"   \u2705 Improvement: {((optimized_avg_enrollment/traditional_avg_enrollment - 1) * 100):.1f}%\")print(\"\\n\u23f1\ufe0f  TIMELINE IMPACT:\")print(f\"   Traditional Timeline: {traditional_timeline_months:.1f} months\")print(f\"   AI-Optimized Timeline: {optimized_timeline_months:.1f} months\")print(f\"   \u2705 Time Saved: {timeline_reduction_months:.1f} months ({timeline_reduction_days:.0f} days)\")print(\"\\n\ud83d\udcb5 COST SAVINGS:\")print(f\"   Delay Cost Savings:       ${delay_savings:,.0f}\")print(f\"   Site Operational Savings: ${site_cost_savings:,.0f}\")print(f\"   \u2705 TOTAL SAVINGS:         ${total_savings:,.0f}\")print(\"\\n\ud83d\udcc8 ADDITIONAL BENEFITS:\")print(f\"   \u2022 Faster time-to-market for life-saving therapies\")print(f\"   \u2022 Reduced sponsor risk and improved competitive position\")print(f\"   \u2022 Better resource allocation (avoid underperforming sites)\")print(f\"   \u2022 Data-driven decisions replace gut feel\")print(\"\\n\" + \"=\" * 70)print(f\"\\n\ud83c\udfaf ROI: ${total_savings:,.0f} savings for a single Phase III trial\")print(f\"\\n\ud83d\udca1 With 10-15 trials/year, annual impact: ${total_savings * 12:,.0f}M\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}